# PDF-chatbot-using-gemini

This script demonstrates how to implement a Retrieval-Augmented Generation (RAG) system using LangChain and Google's Gemini model. It involves loading a PDF document, splitting it into manageable chunks, converting the chunks into vector embeddings using Google's Generative AI, and storing them in a Chroma vector store. The system then retrieves the most relevant documents in response to a user query and generates a concise answer using a language model. This approach allows for efficient and accurate question-answering based on specific document content.


# OUTPUT 
![image](https://github.com/user-attachments/assets/8edd3424-4fb3-412c-bd8a-e177c93e0e6c)
